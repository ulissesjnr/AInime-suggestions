{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e751736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc90c34",
   "metadata": {},
   "source": [
    "# Phase 1 - ETL\n",
    "\n",
    "Here i will load and transform the data i will be using;\n",
    "Originally, that were datasets:\n",
    "- anime_cleaned.csv; (cointains data about the animes)\n",
    "- animelists_cleaned.csv; (contains the data about the users ratings of each anime)\n",
    "- users_cleaned.csv (contains user data)\n",
    "\n",
    "In order to ensure the experiment remains compatible with my systemâ€™s processing capacity, i needed to reduce the data volume, so i opted to:\n",
    "- Remove animes in which the total number of ratings were bellow the median of all anime;\n",
    "- Remove users who had whatch less than the median number of shows or more than the median plus the standart deviation, in order to handle outliers.\n",
    "\n",
    "In this phase i also normalized the values.\n",
    "\n",
    "## Step 1 - Function declaration\n",
    "\n",
    "Here i will declare the functions that will be used for loading and transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5629ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for the raw files\n",
    "datasets_folder_path: str = \"./DataSets\"\n",
    "anime_file_name: str = \"anime_cleaned.csv\"\n",
    "users_file_name: str = \"users_cleaned.csv\"\n",
    "ratings_file_name: str = \"animelists_cleaned.csv\"\n",
    "\n",
    "\n",
    "def generate_key_user_atributes() -> pd.DataFrame :\n",
    "    \"\"\"Generates a dataframe keeping only the user atributes that will be used \n",
    "    Args:\n",
    "        path: String with the original dataset path\n",
    "    Returns:\n",
    "        users: pd.DataFrame containning usersnames, user_ids and number or completed shows\n",
    "    \"\"\"\n",
    "    users = pd.read_csv(f\"{datasets_folder_path}/{users_file_name}\")\n",
    "    users = users[[\"username\",\"user_id\",\"user_completed\"]]\n",
    "    \n",
    "    return users\n",
    "\n",
    "\n",
    "def generate_key_ratings_atributes() -> pd.DataFrame :\n",
    "    \"\"\"Generates a dataframe keeping only the user atributes that will be used \n",
    "    Args:\n",
    "        path: String with the original dataset path\n",
    "    Returns:\n",
    "        ratings: pd.DataFrame containning usersnames, anime_ids and ratings\"\"\"\n",
    "    ratings = pd.read_csv(f\"{datasets_folder_path}/{ratings_file_name}\")\n",
    "    ratings = ratings[[\"username\",\"anime_id\",\"my_score\"]]\n",
    "\n",
    "    return ratings\n",
    "\n",
    "\n",
    "def generate_key_anime_atributes() -> pd.DataFrame :\n",
    "    \"\"\"Generates a dataframe keeping only the user atributes that will be used \n",
    "    Args:\n",
    "        path: String with the original dataset path\n",
    "    Returns:\n",
    "        ratings: pd.DataFrame containning anime_ids and the number of ratings\"\"\"\n",
    "    animes = pd.read_csv(f\"{datasets_folder_path}/{anime_file_name}\")\n",
    "    animes = animes [[\"anime_id\",\"scored_by\"]]\n",
    "\n",
    "    return animes\n",
    "\n",
    "\n",
    "def add_user_data_to_rating(ratings: pd.DataFrame, user_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Merges user data and rating data\n",
    "    Args:\n",
    "        ratings: pd.DataFrame with the ratings\n",
    "        user_data: pd.DataFrame with the user data\n",
    "    Returns:\n",
    "        ratings: pd.DataFrame containing the merged DataFrames\"\"\"\n",
    "    ratings = ratings.merge(user_data, on=\"username\", how=\"inner\")\n",
    "\n",
    "    return ratings\n",
    "\n",
    "\n",
    "def normalize_ratings(ratings: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Normalizes the column \"my_score\", by dividing all values by the biggest value\n",
    "    Args:\n",
    "        ratings: pd.Dataframe with the original data\n",
    "    Returns:\n",
    "        ratings: pd.DataFrame with an aditional column, called \"normalized_score\" \"\"\"\n",
    "    ratings[\"normalized_score\"] = ratings[\"my_score\"] / ratings[\"my_score\"].max()\n",
    "\n",
    "    return ratings\n",
    "\n",
    "\n",
    "def remove_users_with_low_number_of_ratings(users: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Removes users who have rated less than the median number of anime or more than the median plus the standart deviation\n",
    "    Args:\n",
    "        users: pd.DataFrame with user data\n",
    "    Returns:\n",
    "        users: pd.Dataframe filtered, removing the users previously mentioned \"\"\"\n",
    "    std = users[\"user_completed\"].std()\n",
    "    median = users[\"user_completed\"].median()\n",
    "    upper_limit = median + std\n",
    "\n",
    "    users = users.loc[\n",
    "        (users[\"user_completed\"] >= median) & \n",
    "        (users[\"user_completed\"] <= upper_limit)\n",
    "    ]\n",
    "\n",
    "    return users\n",
    "\n",
    "\n",
    "def remove_anime_with_few_ratings(animes: pd.DataFrame):\n",
    "    \"\"\"Removes anime with a number of ratings below the median\n",
    "    Args:\n",
    "        animes: pd.DataFrame with all anime data\n",
    "    Returns:\n",
    "        animes: pd.DataFrame with all anime data, except by those excluded above\"\"\"\n",
    "    median = animes[\"scored_by\"].median()\n",
    "    animes = animes.loc[animes[\"scored_by\"]> median]\n",
    "\n",
    "    return animes\n",
    "\n",
    "def drop_unused_info(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Clean columns that won't be used furthermore\n",
    "    Args:\n",
    "        df: pd.DataFrame\n",
    "    Returns: \n",
    "        df: pd.DataFrame without the columns\"\"\"\n",
    "    df = df.drop(columns=[\"username\",\n",
    "                          \"my_score\",\n",
    "                          \"user_completed\",\n",
    "                          \"scored_by\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53b785a",
   "metadata": {},
   "source": [
    "## Step 2 - Defining a pipeline\n",
    "\n",
    "Here i'll create a pipeline for loading, normalizing and joining the data by using the functions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5b18869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_normalize_and_join() -> pd.DataFrame:\n",
    "    \"\"\"Loads, normalizes and join the 3 main dataframes\n",
    "    Returns:\n",
    "        rating_data: pd.DataFrame containing anime_id, normalized_score and user_id\"\"\"\n",
    "\n",
    "    users = generate_key_user_atributes()\n",
    "    users = remove_users_with_low_number_of_ratings(users)\n",
    "\n",
    "    ratings = generate_key_ratings_atributes()\n",
    "    ratings = normalize_ratings(ratings)\n",
    "    \n",
    "    animes = generate_key_anime_atributes()\n",
    "    animes = remove_anime_with_few_ratings(animes)\n",
    "\n",
    "    rating_data = add_user_data_to_rating(ratings, users)\n",
    "    # this step will remove all ratings from anime with less than the defined number of ratings\n",
    "    rating_data = drop_unused_info(rating_data.merge(animes, on=\"anime_id\", how=\"inner\"))\n",
    "    \n",
    "\n",
    "    return rating_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cf88d8",
   "metadata": {},
   "source": [
    "## Step 2.1 - runing the pipeline and storing the results\n",
    "Run the cell below to execute the load, normalize and join pipeline, also, the following cell can be used to store the results in a .csv file, making it possible to only load the csv file instead of repeting the first steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "720aeb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_data = load_normalize_and_join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c32dc83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_data.to_csv(\"./normalized_joined_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a1b7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_data = pd.read_csv(\"./normalized_joined_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c5ba2c",
   "metadata": {},
   "source": [
    "## Step 3 - Generating a Cosine Similarity Matrix\n",
    "\n",
    "Here i'll create a matrix will all users, all animes, and the values of the normalized scores for each anime and user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbfc2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_anime_matrix(rating_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"creates a matrix with all the values for users as the index and all the values for animes on the columns and fill the values with the ratings, for rated animes and with 0 in case there is not a rating\n",
    "    Args: \n",
    "        rating_data: pd.DataFrame containing user_ids, anime_ids and normalized ratings\n",
    "    Returns: \n",
    "        user_anime_matrix: pd.DataFrame containing a matrix with the source data\"\"\"\n",
    "    user_anime_matrix = rating_data.pivot_table(\n",
    "        index=\"user_id\", columns=\"anime_id\", values=\"normalized_score\").fillna(0)\n",
    "    \n",
    "    return user_anime_matrix\n",
    "\n",
    "\n",
    "def create_similarity_matrix(user_anime_matrix: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"creats a similarity matrix by using an user-anime-rating matrix\n",
    "    Args:\n",
    "        user_anime_matrix: pd.DataFrame with a matrix of user/anime/rating\n",
    "    Returns:\n",
    "        similarity_matrix: pd.DataFrame with the level of similarity between all users\"\"\"\n",
    "    user_similarity = cosine_similarity(user_anime_matrix)\n",
    "    similarity_matrix = pd.DataFrame(user_similarity, index=user_anime_matrix.index, columns=user_anime_matrix.index)\n",
    "\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6ea143",
   "metadata": {},
   "source": [
    "## Step 4 - instantiate the matrix\n",
    "\n",
    "Here i'll simple instantiate the matrixes on local variables, so they can be used later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "550b884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_anime_matrix = create_user_anime_matrix(rating_data)\n",
    "similarity_matrix = create_similarity_matrix(user_anime_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f00c24",
   "metadata": {},
   "source": [
    "## Step 5 - Define the suggestion methods\n",
    "\n",
    "Bellow, there is the definition of the functions used to get similar uses and, afterwards, an anime suggestion list, for an user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8bb3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_users(user_id: int, top_n: int=5) -> list:\n",
    "    \"\"\"Get a list with N most-similar users\n",
    "    Args:\n",
    "        user_id: int id belonged by the user\n",
    "        top_n: int number of most-similar users returned\n",
    "    Returns:\n",
    "        similar: list of user_ids\"\"\"\n",
    "    similar = similarity_matrix[user_id].sort_values(ascending=False)\n",
    "    similar = similar.drop(user_id) \n",
    "    return similar.head(top_n)\n",
    "\n",
    "def suggest_anime(user_id, top_n=10):\n",
    "    \"\"\"Get a dataframe with N anime_ids and average ratings for those animes\n",
    "    Args:\n",
    "        user_id: int id belonged by the user\n",
    "        top_n: int number of anime suggestions\n",
    "    Returns:\n",
    "        non_watched_anime: pd.DataFrame containing anime_ids and average ratings\"\"\"\n",
    "    similar_users = get_similar_users(user_id)\n",
    "    \n",
    "    similar_anime = user_anime_matrix.loc[similar_users.index]\n",
    "    \n",
    "    average_ratings = similar_anime.mean(axis=0)\n",
    "    \n",
    "    watched_anime = user_anime_matrix.loc[user_id]\n",
    "    non_watched_anime = average_ratings[watched_anime == 0]\n",
    "    \n",
    "    return non_watched_anime.sort_values(ascending=False).head(top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eb98f6",
   "metadata": {},
   "source": [
    "## Step 6 - Run the suggestion\n",
    "\n",
    "Bellow, the method can be executed to return N suggestions for an user_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39efb2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anime_id\n",
       "60      0.86\n",
       "488     0.84\n",
       "1887    0.84\n",
       "30      0.82\n",
       "120     0.80\n",
       "387     0.80\n",
       "1       0.78\n",
       "50      0.78\n",
       "2904    0.78\n",
       "28      0.78\n",
       "889     0.74\n",
       "245     0.72\n",
       "45      0.70\n",
       "61      0.70\n",
       "2001    0.68\n",
       "202     0.66\n",
       "467     0.64\n",
       "97      0.62\n",
       "227     0.62\n",
       "2025    0.60\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggest_anime(user_id=66, top_n=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
