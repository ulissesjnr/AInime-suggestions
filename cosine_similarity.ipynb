{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e751736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc90c34",
   "metadata": {},
   "source": [
    "# Phase 1 - ETL\n",
    "\n",
    "Here i will load and transform the data i will be using;\n",
    "Originally, that were datasets:\n",
    "- anime_cleaned.csv; (cointains data about the animes)\n",
    "- animelists_cleaned.csv; (contains the data about the users ratings of each anime)\n",
    "- users_cleaned.csv (contains user data)\n",
    "\n",
    "In order to ensure the experiment remains compatible with my systemâ€™s processing capacity, i needed to reduce the data volume, so i opted to:\n",
    "- Remove animes in which the total number of ratings were bellow the median of all anime;\n",
    "- Remove users who had whatch less than the median number of shows or more than the median plus the standart deviation, in order to handle outliers.\n",
    "\n",
    "In this phase i also normalized the values.\n",
    "\n",
    "## Step 1 - Function declaration\n",
    "\n",
    "Here i will declare the functions that will be used for loading and transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5629ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for the raw files\n",
    "datasets_folder_path: str = \"./DataSets\"\n",
    "anime_file_name: str = \"anime_cleaned.csv\"\n",
    "users_file_name: str = \"users_cleaned.csv\"\n",
    "ratings_file_name: str = \"animelists_cleaned.csv\"\n",
    "\n",
    "\n",
    "def generate_key_user_atributes() -> pd.DataFrame :\n",
    "    \"\"\"Generates a dataframe keeping only the user atributes that will be used \n",
    "    Args:\n",
    "        path: String with the original dataset path\n",
    "    Returns:\n",
    "        users: pd.DataFrame containning usersnames, user_ids and number or completed shows\n",
    "    \"\"\"\n",
    "    users = pd.read_csv(f\"{datasets_folder_path}/{users_file_name}\")\n",
    "    users = users[[\"username\",\"user_id\",\"user_completed\"]]\n",
    "    \n",
    "    return users\n",
    "\n",
    "\n",
    "def generate_key_ratings_atributes() -> pd.DataFrame :\n",
    "    \"\"\"Generates a dataframe keeping only the user atributes that will be used \n",
    "    Args:\n",
    "        path: String with the original dataset path\n",
    "    Returns:\n",
    "        ratings: pd.DataFrame containning usersnames, anime_ids and ratings\"\"\"\n",
    "    ratings = pd.read_csv(f\"{datasets_folder_path}/{ratings_file_name}\")\n",
    "    ratings = ratings[[\"username\",\"anime_id\",\"my_score\"]]\n",
    "\n",
    "    return ratings\n",
    "\n",
    "\n",
    "def generate_key_anime_atributes() -> pd.DataFrame :\n",
    "    \"\"\"Generates a dataframe keeping only the user atributes that will be used \n",
    "    Args:\n",
    "        path: String with the original dataset path\n",
    "    Returns:\n",
    "        ratings: pd.DataFrame containning anime_ids and the number of ratings\"\"\"\n",
    "    animes = pd.read_csv(f\"{datasets_folder_path}/{anime_file_name}\")\n",
    "    animes = animes [[\"anime_id\",\"scored_by\"]]\n",
    "\n",
    "    return animes\n",
    "\n",
    "\n",
    "def add_user_data_to_rating(ratings: pd.DataFrame, user_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Merges user data and rating data\n",
    "    Args:\n",
    "        ratings: pd.DataFrame with the ratings\n",
    "        user_data: pd.DataFrame with the user data\n",
    "    Returns:\n",
    "        ratings: pd.DataFrame containing the merged DataFrames\"\"\"\n",
    "    ratings = ratings.merge(user_data, on=\"username\", how=\"inner\")\n",
    "\n",
    "    return ratings\n",
    "\n",
    "\n",
    "def normalize_ratings(ratings: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Normalizes the column \"my_score\", by dividing all values by the biggest value\n",
    "    Args:\n",
    "        ratings: pd.Dataframe with the original data\n",
    "    Returns:\n",
    "        ratings: pd.DataFrame with an aditional column, called \"normalized_score\" \"\"\"\n",
    "    ratings[\"normalized_score\"] = ratings[\"my_score\"] / ratings[\"my_score\"].max()\n",
    "\n",
    "    return ratings\n",
    "\n",
    "\n",
    "def remove_users_with_low_number_of_ratings(users: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Removes users who have rated less than the median number of anime or more than the median plus the standart deviation\n",
    "    Args:\n",
    "        users: pd.DataFrame with user data\n",
    "    Returns:\n",
    "        users: pd.Dataframe filtered, removing the users previously mentioned \"\"\"\n",
    "    std = users[\"user_completed\"].std()\n",
    "    median = users[\"user_completed\"].median()\n",
    "    upper_limit = median + std\n",
    "\n",
    "    users = users.loc[\n",
    "        (users[\"user_completed\"] >= median) & \n",
    "        (users[\"user_completed\"] <= upper_limit)\n",
    "    ]\n",
    "\n",
    "    return users\n",
    "\n",
    "\n",
    "def remove_anime_with_few_ratings(animes: pd.DataFrame):\n",
    "    \"\"\"Removes anime with a number of ratings below the median\n",
    "    Args:\n",
    "        animes: pd.DataFrame with all anime data\n",
    "    Returns:\n",
    "        animes: pd.DataFrame with all anime data, except by those excluded above\"\"\"\n",
    "    median = animes[\"scored_by\"].median()\n",
    "    animes = animes.loc[animes[\"scored_by\"]> median]\n",
    "\n",
    "    return animes\n",
    "\n",
    "def drop_unused_info(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Clean columns that won't be used furthermore\n",
    "    Args:\n",
    "        df: pd.DataFrame\n",
    "    Returns: \n",
    "        df: pd.DataFrame without the columns\"\"\"\n",
    "    df = df.drop(columns=[\"username\",\n",
    "                          \"my_score\",\n",
    "                          \"user_completed\",\n",
    "                          \"scored_by\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53b785a",
   "metadata": {},
   "source": [
    "## Step 2 - Defining a pipeline\n",
    "\n",
    "Here i'll create a pipeline for loading, normalizing and joining the data by using the functions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5b18869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_normalize_and_join() -> pd.DataFrame:\n",
    "    \"\"\"Loads, normalizes and join the 3 main dataframes\n",
    "    Returns:\n",
    "        rating_data: pd.DataFrame containing anime_id, normalized_score and user_id\"\"\"\n",
    "\n",
    "    users = generate_key_user_atributes()\n",
    "    users = remove_users_with_low_number_of_ratings(users)\n",
    "\n",
    "    ratings = generate_key_ratings_atributes()\n",
    "    ratings = normalize_ratings(ratings)\n",
    "    \n",
    "    animes = generate_key_anime_atributes()\n",
    "    animes = remove_anime_with_few_ratings(animes)\n",
    "\n",
    "    rating_data = add_user_data_to_rating(ratings, users)\n",
    "    # this step will remove all ratings from anime with less than the defined number of ratings\n",
    "    rating_data = drop_unused_info(rating_data.merge(animes, on=\"anime_id\", how=\"inner\"))\n",
    "    \n",
    "\n",
    "    return rating_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cf88d8",
   "metadata": {},
   "source": [
    "## Step 2.1 - runing the pipeline and storing the results\n",
    "Run the cell below to execute the load, normalize and join pipeline, also, the following cell can be used to store the results in a .csv file, making it possible to only load the csv file instead of repeting the first steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "720aeb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_data = load_normalize_and_join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c32dc83a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrating_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./normalized_joined_data.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sessi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sessi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:3986\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3975\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3977\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3978\u001b[39m     frame=df,\n\u001b[32m   3979\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3983\u001b[39m     decimal=decimal,\n\u001b[32m   3984\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3986\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3987\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3988\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3989\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sessi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sessi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:270\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[32m    252\u001b[39m     \u001b[38;5;28mself\u001b[39m.filepath_or_buffer,\n\u001b[32m    253\u001b[39m     \u001b[38;5;28mself\u001b[39m.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    258\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sessi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:275\u001b[39m, in \u001b[36mCSVFormatter._save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._need_to_save_header:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28mself\u001b[39m._save_header()\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sessi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:313\u001b[39m, in \u001b[36mCSVFormatter._save_body\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m start_i >= end_i:\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sessi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:323\u001b[39m, in \u001b[36mCSVFormatter._save_chunk\u001b[39m\u001b[34m(self, start_i, end_i)\u001b[39m\n\u001b[32m    320\u001b[39m res = df._get_values_for_csv(**\u001b[38;5;28mself\u001b[39m._number_format)\n\u001b[32m    321\u001b[39m data = \u001b[38;5;28mlist\u001b[39m(res._iter_column_arrays())\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m ix = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mslicer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_values_for_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_number_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m libwriters.write_csv_rows(\n\u001b[32m    325\u001b[39m     data,\n\u001b[32m    326\u001b[39m     ix,\n\u001b[32m   (...)\u001b[39m\u001b[32m    329\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer,\n\u001b[32m    330\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sessi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:1486\u001b[39m, in \u001b[36mIndex._get_values_for_csv\u001b[39m\u001b[34m(self, na_rep, decimal, float_format, date_format, quoting)\u001b[39m\n\u001b[32m   1476\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_values_for_csv\u001b[39m(\n\u001b[32m   1477\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1478\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1483\u001b[39m     quoting=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1484\u001b[39m ) -> npt.NDArray[np.object_]:\n\u001b[32m   1485\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m get_values_for_csv(\n\u001b[32m-> \u001b[39m\u001b[32m1486\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_values\u001b[49m,\n\u001b[32m   1487\u001b[39m         na_rep=na_rep,\n\u001b[32m   1488\u001b[39m         decimal=decimal,\n\u001b[32m   1489\u001b[39m         float_format=float_format,\n\u001b[32m   1490\u001b[39m         date_format=date_format,\n\u001b[32m   1491\u001b[39m         quoting=quoting,\n\u001b[32m   1492\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sessi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5178\u001b[39m, in \u001b[36mIndex._values\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   5154\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m   5155\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_values\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> ExtensionArray | np.ndarray:\n\u001b[32m   5156\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5157\u001b[39m \u001b[33;03m    The best array representation.\u001b[39;00m\n\u001b[32m   5158\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5176\u001b[39m \u001b[33;03m    values : Values\u001b[39;00m\n\u001b[32m   5177\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/properties.pyx:36\u001b[39m, in \u001b[36mpandas._libs.properties.CachedProperty.__get__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sessi\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:244\u001b[39m, in \u001b[36mRangeIndex._data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_data\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> np.ndarray:  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    240\u001b[39m \u001b[33;03m    An int array that for performance reasons is created only when needed.\u001b[39;00m\n\u001b[32m    241\u001b[39m \n\u001b[32m    242\u001b[39m \u001b[33;03m    The constructed array is saved in ``_cache``.\u001b[39;00m\n\u001b[32m    243\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mint64\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "rating_data.to_csv(\"./normalized_joined_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33a1b7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_data = pd.read_csv(\"./normalized_joined_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c5ba2c",
   "metadata": {},
   "source": [
    "## Step 3 - Generating a Cosine Similarity Matrix\n",
    "\n",
    "Here i'll create a matrix will all users, all animes, and the values of the normalized scores for each anime and user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abbfc2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_anime_matrix(rating_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"creates a matrix with all the values for users as the index and all the values for animes on the columns and fill the values with the ratings, for rated animes and with 0 in case there is not a rating\n",
    "    Args: \n",
    "        rating_data: pd.DataFrame containing user_ids, anime_ids and normalized ratings\n",
    "    Returns: \n",
    "        user_anime_matrix: pd.DataFrame containing a matrix with the source data\"\"\"\n",
    "    user_anime_matrix = rating_data.pivot_table(\n",
    "        index=\"user_id\", columns=\"anime_id\", values=\"normalized_score\").fillna(0)\n",
    "    \n",
    "    return user_anime_matrix\n",
    "\n",
    "\n",
    "def create_similarity_matrix(user_anime_matrix: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"creats a similarity matrix by using an user-anime-rating matrix\n",
    "    Args:\n",
    "        user_anime_matrix: pd.DataFrame with a matrix of user/anime/rating\n",
    "    Returns:\n",
    "        similarity_matrix: pd.DataFrame with the level of similarity between all users\"\"\"\n",
    "    user_similarity = cosine_similarity(user_anime_matrix)\n",
    "    similarity_matrix = pd.DataFrame(user_similarity, index=user_anime_matrix.index, columns=user_anime_matrix.index)\n",
    "\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6ea143",
   "metadata": {},
   "source": [
    "## Step 4 - instantiate the matrix\n",
    "\n",
    "Here i'll simple instantiate the matrixes on local variables, so they can be used later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "550b884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_anime_matrix = create_user_anime_matrix(rating_data)\n",
    "similarity_matrix = create_similarity_matrix(user_anime_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f00c24",
   "metadata": {},
   "source": [
    "## Step 5 - Define the suggestion methods\n",
    "\n",
    "Bellow, there is the definition of the functions used to get similar uses and, afterwards, an anime suggestion list, for an user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8bb3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_users(user_id: int, top_n: int=50) -> list:\n",
    "    \"\"\"Get a list with N most-similar users\n",
    "    Args:\n",
    "        user_id: int id belonged by the user\n",
    "        top_n: int number of most-similar users returned\n",
    "    Returns:\n",
    "        similar: list of user_ids\"\"\"\n",
    "    similar = similarity_matrix[user_id].sort_values(ascending=False)\n",
    "    similar = similar.drop(user_id) \n",
    "    return similar.head(top_n)\n",
    "\n",
    "def suggest_anime(user_id, top_n=10):\n",
    "    \"\"\"Get a dataframe with N anime_ids and average ratings for those animes\n",
    "    Args:\n",
    "        user_id: int id belonged by the user\n",
    "        top_n: int number of anime suggestions\n",
    "    Returns:\n",
    "        non_watched_anime: pd.DataFrame containing anime_ids and average ratings\"\"\"\n",
    "    similar_users = get_similar_users(user_id)\n",
    "    \n",
    "    similar_anime = user_anime_matrix.loc[similar_users.index]\n",
    "    \n",
    "    average_ratings = similar_anime.mean(axis=0)\n",
    "    \n",
    "    watched_anime = user_anime_matrix.loc[user_id]\n",
    "    non_watched_anime = average_ratings[watched_anime == 0]\n",
    "\n",
    "    anime = pd.read_csv(f\"{datasets_folder_path}/{anime_file_name}\")\n",
    "    non_watched_anime = non_watched_anime.reset_index()\n",
    "    non_watched_anime = non_watched_anime.merge(anime[[\"anime_id\",\"title\"]], on=\"anime_id\", how=\"left\")\n",
    "    \n",
    "    return non_watched_anime.sort_values(by=non_watched_anime.columns[1], ascending=False).head(top_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79eb98f6",
   "metadata": {},
   "source": [
    "## Step 6 - Run the suggestion\n",
    "\n",
    "Bellow, the method can be executed to return N suggestions for an user_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "39efb2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>0</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>1735</td>\n",
       "      <td>0.778</td>\n",
       "      <td>Naruto: Shippuuden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.736</td>\n",
       "      <td>Trigun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>1575</td>\n",
       "      <td>0.734</td>\n",
       "      <td>Code Geass: Hangyaku no Lelouch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>1559</td>\n",
       "      <td>0.682</td>\n",
       "      <td>Shijou Saikyou no Deshi Kenichi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>71</td>\n",
       "      <td>0.672</td>\n",
       "      <td>Full Metal Panic!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>270</td>\n",
       "      <td>0.668</td>\n",
       "      <td>Hellsing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>2001</td>\n",
       "      <td>0.638</td>\n",
       "      <td>Tengen Toppa Gurren Lagann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>1818</td>\n",
       "      <td>0.628</td>\n",
       "      <td>Claymore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>889</td>\n",
       "      <td>0.622</td>\n",
       "      <td>Black Lagoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>2904</td>\n",
       "      <td>0.610</td>\n",
       "      <td>Code Geass: Hangyaku no Lelouch R2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>2025</td>\n",
       "      <td>0.584</td>\n",
       "      <td>Darker than Black: Kuro no Keiyakusha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>72</td>\n",
       "      <td>0.578</td>\n",
       "      <td>Full Metal Panic? Fumoffu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>392</td>\n",
       "      <td>0.552</td>\n",
       "      <td>Yuuâ˜†Yuuâ˜†Hakusho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>73</td>\n",
       "      <td>0.528</td>\n",
       "      <td>Full Metal Panic! The Second Raid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>355</td>\n",
       "      <td>0.516</td>\n",
       "      <td>Shakugan no Shana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>249</td>\n",
       "      <td>0.512</td>\n",
       "      <td>InuYasha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>1519</td>\n",
       "      <td>0.504</td>\n",
       "      <td>Black Lagoon: The Second Barrage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>1482</td>\n",
       "      <td>0.492</td>\n",
       "      <td>D.Gray-man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>264</td>\n",
       "      <td>0.486</td>\n",
       "      <td>Hajime no Ippo: Champion Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30</td>\n",
       "      <td>0.470</td>\n",
       "      <td>Neon Genesis Evangelion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     anime_id      0                                  title\n",
       "724      1735  0.778                     Naruto: Shippuuden\n",
       "1           6  0.736                                 Trigun\n",
       "672      1575  0.734        Code Geass: Hangyaku no Lelouch\n",
       "661      1559  0.682        Shijou Saikyou no Deshi Kenichi\n",
       "29         71  0.672                      Full Metal Panic!\n",
       "155       270  0.668                               Hellsing\n",
       "773      2001  0.638             Tengen Toppa Gurren Lagann\n",
       "738      1818  0.628                               Claymore\n",
       "450       889  0.622                           Black Lagoon\n",
       "902      2904  0.610     Code Geass: Hangyaku no Lelouch R2\n",
       "777      2025  0.584  Darker than Black: Kuro no Keiyakusha\n",
       "30         72  0.578              Full Metal Panic? Fumoffu\n",
       "218       392  0.552                        Yuuâ˜†Yuuâ˜†Hakusho\n",
       "31         73  0.528      Full Metal Panic! The Second Raid\n",
       "201       355  0.516                      Shakugan no Shana\n",
       "141       249  0.512                               InuYasha\n",
       "645      1519  0.504       Black Lagoon: The Second Barrage\n",
       "636      1482  0.492                             D.Gray-man\n",
       "152       264  0.486          Hajime no Ippo: Champion Road\n",
       "11         30  0.470                Neon Genesis Evangelion"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggest_anime(user_id=120, top_n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a307dd0",
   "metadata": {},
   "source": [
    "# Bonus, adding aditional costum users to the matrix\n",
    "\n",
    "An user can be added by appending it to the inicial user/anime/ratings dataframe, that can be done by gerating the user data, creating a new id and rating some animes in a csv, for instance:\n",
    "- use the user id \"123456789\";\n",
    "- find the id of some anime you like;\n",
    "- rate with ratings from 0 to 1;\n",
    "\n",
    "you can find the anime id using the 2 cells bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ceeae317",
   "metadata": {},
   "outputs": [],
   "source": [
    "animes = pd.read_csv(f\"{datasets_folder_path}/{anime_file_name}\")\n",
    "animes = animes.loc[animes[\"scored_by\"]> (animes[\"scored_by\"].median())]\n",
    "animes = animes[[\"anime_id\",\"title\"]]\n",
    "\n",
    "def get_animes(query: str) -> pd.DataFrame :\n",
    "    \"\"\"Get a list of anime_ids and titles\n",
    "    Args:\n",
    "        query: str with the name you look for\n",
    "    Returns:\n",
    "        results: pd.Dataframe with the filter results\"\"\"\n",
    "    results = animes[animes[\"title\"].str.contains(query, case=False, na=False)]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "43505be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4942</th>\n",
       "      <td>33142</td>\n",
       "      <td>Re:Zero kara Hajimeru Break Time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5137</th>\n",
       "      <td>31240</td>\n",
       "      <td>Re:Zero kara Hajimeru Isekai Seikatsu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      anime_id                                  title\n",
       "4942     33142       Re:Zero kara Hajimeru Break Time\n",
       "5137     31240  Re:Zero kara Hajimeru Isekai Seikatsu"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_animes(\"re:zero\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2564831",
   "metadata": {},
   "source": [
    "# list exemple\n",
    "- anime_id,normalized_score,user_id\n",
    "- 31240, 1, 123456789,\n",
    "- 29803, 1, 123456789,\n",
    "- 269, 0.8, 123456789,\n",
    "- 14813, 0.8, 123456789\n",
    "\n",
    "add your list to the ratings list, bellow and re-run the similarity matrix (its important to note that the most anime there is in your list, the accuracy increases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a097bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "my_list = \"\"\"anime_id,normalized_score,user_id\n",
    "31240, 1, 123456789,\n",
    "29803, 1, 123456789,\n",
    "269, 0.8, 123456789,\n",
    "14813, 0.8, 123456789\"\"\"\n",
    "my_list = pd.read_csv(StringIO(my_list),index_col=False)\n",
    "\n",
    "rating_data = pd.concat([rating_data, my_list], ignore_index=True)\n",
    "\n",
    "user_anime_matrix = create_user_anime_matrix(rating_data)\n",
    "similarity_matrix = create_similarity_matrix(user_anime_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bafa3f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>0</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2904</th>\n",
       "      <td>31964</td>\n",
       "      <td>0.346</td>\n",
       "      <td>Boku no Hero Academia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>11757</td>\n",
       "      <td>0.308</td>\n",
       "      <td>Sword Art Online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>1735</td>\n",
       "      <td>0.296</td>\n",
       "      <td>Naruto: Shippuuden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>1535</td>\n",
       "      <td>0.286</td>\n",
       "      <td>Death Note</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>30276</td>\n",
       "      <td>0.280</td>\n",
       "      <td>One Punch Man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21</td>\n",
       "      <td>0.278</td>\n",
       "      <td>One Piece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>2904</td>\n",
       "      <td>0.272</td>\n",
       "      <td>Code Geass: Hangyaku no Lelouch R2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>1575</td>\n",
       "      <td>0.246</td>\n",
       "      <td>Code Geass: Hangyaku no Lelouch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>16498</td>\n",
       "      <td>0.244</td>\n",
       "      <td>Shingeki no Kyojin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>33486</td>\n",
       "      <td>0.232</td>\n",
       "      <td>Boku no Hero Academia 2nd Season</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      anime_id      0                               title\n",
       "2904     31964  0.346               Boku no Hero Academia\n",
       "1854     11757  0.308                    Sword Art Online\n",
       "833       1735  0.296                  Naruto: Shippuuden\n",
       "761       1535  0.286                          Death Note\n",
       "2720     30276  0.280                       One Punch Man\n",
       "11          21  0.278                           One Piece\n",
       "1013      2904  0.272  Code Geass: Hangyaku no Lelouch R2\n",
       "781       1575  0.246     Code Geass: Hangyaku no Lelouch\n",
       "2133     16498  0.244                  Shingeki no Kyojin\n",
       "3076     33486  0.232    Boku no Hero Academia 2nd Season"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suggest_anime(123456789)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
